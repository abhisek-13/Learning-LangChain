{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgIypBz1jO5B",
        "outputId": "162627c8-7ab2-4426-8e39-cf61f90bb662"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.10/dist-packages (2.0.7)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.3.28)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.10/dist-packages (0.2.60)\n",
            "Requirement already satisfied: langchain-mongodb in /usr/local/lib/python3.10/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.9.2)\n",
            "Requirement already satisfied: langchain-huggingface in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: langchain-chroma in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: langchain-nvidia-ai-endpoints in /usr/local/lib/python3.10/dist-packages (0.3.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.7.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-generativeai<0.9.0,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from langchain_google_genai) (0.8.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from langgraph) (2.0.9)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.1.48)\n",
            "Requirement already satisfied: motor<4.0,>=3.5 in /usr/local/lib/python3.10/dist-packages (from langchain-mongodb) (3.6.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.27.0)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (3.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.20.3)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.46.3)\n",
            "Requirement already satisfied: chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.5.23)\n",
            "Requirement already satisfied: fastapi<1,>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from langchain-chroma) (0.115.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: pillow<11.0.0,>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain-nvidia-ai-endpoints) (10.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2.post1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.6 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.7.6)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.34.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.4)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.20.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.68.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (4.2.1)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.15.1)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (31.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (5.0.1)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (13.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi<1,>=0.95.2->langchain-chroma) (0.41.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.10)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (5.29.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2024.10.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.5)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.8.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.2.2)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.9)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.5.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.29.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.50b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.17.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.5.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.0.3)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (14.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (4.1.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (1.2.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (3.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.9.0,>=0.8.0->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb!=0.5.4,!=0.5.5,<0.6.0,>=0.4.0->langchain-chroma) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain_community pypdf langchain_google_genai langchain-core langgraph langchain-mongodb pymongo langchain-huggingface langchain-chroma beautifulsoup4 tiktoken langchain-nvidia-ai-endpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atx5nim1g2uK"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ['LANGCHAIN_TRACING_V2']=\"true\"\n",
        "os.environ['LANGCHAIN_ENDPOINT']=\"https://api.smith.langchain.com\"\n",
        "os.environ['LANGCHAIN_API_KEY']=\"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\"\n",
        "os.environ['LANGCHAIN_PROJECT']=\"Simple-ChatBot\"\n",
        "os.environ['TAVILY_API_KEY']=\"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\"\n",
        "\n",
        "os.environ['GOOGLE_API_KEY'] = \"AIzaSyAT7Dd2zpbEfQymebIeZW8Fzo-5WgpRigc\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9T6vdL8y2YH"
      },
      "source": [
        "#Simple Chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iT0GaXbloyde",
        "outputId": "e681a978-a64b-41b5-e9b3-7e5b4fd5432a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Hi Abhisek!  It's nice to meet you. How can I help you today?\\n\""
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema import HumanMessage\n",
        "\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0,max_tokens=None,timeout=None,max_retries=2)\n",
        "\n",
        "model.invoke([HumanMessage(content = 'Hi, my name is abhisek')]).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "VgDUiaKA1Z4r",
        "outputId": "41595f5f-33fb-48a7-e586-7656bc368744"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'You said your name is Abhisek.\\n'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import AIMessage\n",
        "\n",
        "model.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"Hi! I'm Abhisek\"),\n",
        "        AIMessage(content=\"Hello Abhisek! How can I assist you today?\"),\n",
        "        HumanMessage(content=\"What's my name?\"),\n",
        "    ]\n",
        ").content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoC_m0OLzEH9"
      },
      "source": [
        "# Message Persistence (Remembering the previous context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WsPAa30iCP2"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import START, MessagesState, StateGraph\n",
        "\n",
        "# Define a new graph\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "\n",
        "# Define the function that calls the model\n",
        "def call_model(state: MessagesState):\n",
        "    response = model.invoke(state[\"messages\"])\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "# Define the (single) node in the graph\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "# Add memory\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOYdqL3tovjv"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7qFNPqJpFbC",
        "outputId": "ea461055-f26f-4cb4-a45a-c31415da24b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Hi Abhisek! It's nice to meet you. How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "query = \"Hi! I'm Abhisek.\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()  # output contains all messages in state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EN3kTXxcpNNI",
        "outputId": "731baca1-870d-483f-dad2-297a41317b8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Your name is Abhisek.  You told me at the beginning of our conversation.\n"
          ]
        }
      ],
      "source": [
        "query = \"What's my name?\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_xl-43xpkEj",
        "outputId": "aeeadbf9-a76f-4c35-fe8a-d3fb293253b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I don't know your name. I have no memory of past conversations and no access to any personal information about you.  You would have to tell me your name for me to know it.\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc234\"}}\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8feHxVvdzX48"
      },
      "source": [
        "#Prompt template"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pA-MZ-USqYx5"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\",\"You talk like a Prime Minister. Answer all questions to the best of your ability.\",),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "\n",
        "def call_model(state: MessagesState):\n",
        "    prompt = prompt_template.invoke(state)\n",
        "    response = model.invoke(prompt)\n",
        "    return {\"messages\": response}\n",
        "\n",
        "\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTIkL578soO1",
        "outputId": "9f511f05-d608-40eb-fdc3-2b45682aa601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "It's a pleasure to meet you, Abhisek. How can I be of assistance today?\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc345\"}}\n",
        "query = \"Hi! I'm Abhisek.\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke({\"messages\": input_messages}, config)\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBugzBNMstxC"
      },
      "outputs": [],
      "source": [
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are a Customer care assistant. Answer all questions to the best of your ability in {language}.\",\n",
        "        ),\n",
        "        MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5bL8PVZuLKl"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing_extensions import Annotated, TypedDict\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "    language: str\n",
        "\n",
        "\n",
        "workflow = StateGraph(state_schema=State)\n",
        "\n",
        "\n",
        "def call_model(state: State):\n",
        "    prompt = prompt_template.invoke(state)\n",
        "    response = model.invoke(prompt)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFVnU3Afu6DW",
        "outputId": "8a34ddc8-fb55-4ef4-9b83-557098fc094b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "¡Hola Bob! ¿En qué puedo ayudarte hoy?\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc456\"}}\n",
        "query = \"Hi! I'm Bob.\"\n",
        "language = \"Spanish\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke(\n",
        "    {\"messages\": input_messages, \"language\": language},\n",
        "    config,\n",
        ")\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGuZd3sGu94C",
        "outputId": "5983c7b5-8e46-4b3d-d74a-c73ef98d7711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Me dijiste que tu nombre es Bob.\n"
          ]
        }
      ],
      "source": [
        "query = \"What is my name?\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "output = app.invoke(\n",
        "    {\"messages\": input_messages},\n",
        "    config,\n",
        ")\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9GHCSzTzgwx"
      },
      "source": [
        "#Managing Conversation History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6a2rckEvTfl",
        "outputId": "59f9535d-b93d-45bd-f37f-ca8cb3ccf066"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content=\"hi! I'm Abhisek.\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import SystemMessage, trim_messages\n",
        "\n",
        "trimmer = trim_messages(\n",
        "    max_tokens=65,\n",
        "    strategy=\"last\",\n",
        "    token_counter=model,\n",
        "    include_system=True,\n",
        "    allow_partial=True,\n",
        "    start_on=\"human\",\n",
        ")\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"you're a good assistant\"),\n",
        "    HumanMessage(content=\"hi! I'm Abhisek.\"),\n",
        "    AIMessage(content=\"hi!\"),\n",
        "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
        "    AIMessage(content=\"nice\"),\n",
        "    HumanMessage(content=\"whats 2 + 2\"),\n",
        "    AIMessage(content=\"4\")\n",
        "]\n",
        "\n",
        "trimmer.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgEpWOsBzwCI"
      },
      "outputs": [],
      "source": [
        "workflow = StateGraph(state_schema=State)\n",
        "\n",
        "\n",
        "def call_model(state: State):\n",
        "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
        "    prompt = prompt_template.invoke(\n",
        "        {\"messages\": trimmed_messages, \"language\": state[\"language\"]}\n",
        "    )\n",
        "    response = model.invoke(prompt)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Z03hTGEE0Wta",
        "outputId": "1462b037-7650-4be2-d6da-d5a0b22b00a9"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Unexpected message with type <class 'langchain_core.messages.system.SystemMessage'> at the position 1.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3271c8265760>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minput_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessages\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mHumanMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m output = app.invoke(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"language\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   1934\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1936\u001b[0;31m         for chunk in self.stream(\n\u001b[0m\u001b[1;32m   1937\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/__init__.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1654\u001b[0m                 \u001b[0;31m# with channel updates applied only at the transition between steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_channels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                     for _ in runner.tick(\n\u001b[0m\u001b[1;32m   1657\u001b[0m                         \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m                         \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/runner.py\u001b[0m in \u001b[0;36mtick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m                 run_with_retry(\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mretry_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/pregel/retry.py\u001b[0m in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;31m# run the task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mParentCommand\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONF\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_CHECKPOINT_NS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 )\n\u001b[1;32m    407\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langgraph/utils/runnable.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_set_config_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRunnable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-b94c8cb2f6ad>\u001b[0m in \u001b[0;36mcall_model\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrimmed_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"language\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"language\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     )\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         return cast(\n\u001b[1;32m    285\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    785\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         flattened_outputs = [\n\u001b[1;32m    645\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 results.append(\n\u001b[0;32m--> 633\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    634\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    852\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     ) -> ChatResult:\n\u001b[0;32m--> 935\u001b[0;31m         request = self._prepare_request(\n\u001b[0m\u001b[1;32m    936\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m             \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_prepare_request\u001b[0;34m(self, messages, stop, tools, functions, safety_settings, tool_config, tool_choice, generation_config, cached_content)\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mformatted_tools\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconvert_to_genai_function_declarations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         system_instruction, history = _parse_chat_history(\n\u001b[0m\u001b[1;32m   1166\u001b[0m             \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m             \u001b[0mconvert_system_message_to_human\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_system_message_to_human\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_parse_chat_history\u001b[0;34m(input_messages, convert_system_message_to_human)\u001b[0m\n\u001b[1;32m    400\u001b[0m             ]\n\u001b[1;32m    401\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    403\u001b[0m                 \u001b[0;34mf\"Unexpected message with type {type(message)} at the position {i}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: Unexpected message with type <class 'langchain_core.messages.system.SystemMessage'> at the position 1."
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc567\"}}\n",
        "query = \"What is my name?\"\n",
        "language = \"English\"\n",
        "\n",
        "input_messages = messages + [HumanMessage(query)]\n",
        "output = app.invoke(\n",
        "    {\"messages\": input_messages, \"language\": language},\n",
        "    config,\n",
        ")\n",
        "output[\"messages\"][-1].pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AY0N3AIi0liC",
        "outputId": "b647c672-49fa-44af-f192-5fd070512963"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Abhi\n",
            "sek, the old lighthouse keeper, squinted at the churning grey sea.  \n",
            "For fifty years, he'd watched the waves crash against the craggy cliffs\n",
            ", their rhythm as familiar as his own heartbeat.  Tonight, though, something was different.  A strange, shimmering light pulsed beneath the waves, growing brighter\n",
            " with each passing moment.  He’d seen phosphorescent plankton before, but this was… otherworldly.\n",
            "\n",
            "He gripped the railing, his knuckles white\n",
            ".  Suddenly, the light erupted from the water, a column of pure, iridescent blue reaching towards the stormy sky.  A creature emerged, sleek and silver, with eyes that glowed like twin moons.  It hovered in the air,\n",
            " its form shifting and shimmering, before settling into the shape of a woman with flowing, seaweed-green hair.\n",
            "\n",
            "She smiled, a radiant, almost blinding smile.  \"Lost, keeper?\" she asked, her voice like the chime of\n",
            " distant bells.\n",
            "\n",
            "Abhisek, usually a man of few words, found himself speechless.  He shook his head, mesmerized.  Lost?  He'd never felt more found.\n",
            "\n",
            "The woman laughed, a sound like the whispering of waves on a summer's night.  \"Then perhaps,\" she\n",
            " said, extending a hand towards him, \"you'll show me the way?\"\n",
            "\n",
            "And Abhisek, the keeper of the light, found himself stepping away from the beacon he'd guarded for so long, drawn towards the unknown depths of the sea.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
        "query = \"Hi I'm Abhisek, tell me a short story.\"\n",
        "language = \"English\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "for chunk, metadata in app.stream(\n",
        "    {\"messages\": input_messages, \"language\": language},\n",
        "    config,\n",
        "    stream_mode=\"messages\",\n",
        "):\n",
        "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
        "        print(chunk.content, end=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAQYc7nFWysj",
        "outputId": "7e3b6191-8a1d-4dc1-96af-b5d018db359b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You\n",
            " asked me to tell you a short story.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"abc789\"}}\n",
        "query = \"What is the question i have asked you previously?\"\n",
        "language = \"English\"\n",
        "\n",
        "input_messages = [HumanMessage(query)]\n",
        "for chunk, metadata in app.stream(\n",
        "    {\"messages\": input_messages, \"language\": language},\n",
        "    config,\n",
        "    stream_mode=\"messages\",\n",
        "):\n",
        "    if isinstance(chunk, AIMessage):  # Filter to just model responses\n",
        "        print(chunk.content, end=\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWGAr1VUghFs"
      },
      "source": [
        "#Build an Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jchvTObQXiRV",
        "outputId": "bda9dc0b-67ed-41a0-b236-21fbf4bf6ecf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content=\"Hi Abhisek! It's nice to meet you.  Bangalore is a wonderful city!  Is there anything I can help you with today?\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-f8812c43-f857-4054-87e2-a0e3fb38da6a-0', usage_metadata={'input_tokens': 86, 'output_tokens': 31, 'total_tokens': 117, 'input_token_details': {'cache_read': 0}})]}}\n",
            "----\n",
            "{'agent': {'messages': [AIMessage(content='I cannot directly access information about the weather in Bangalore. I can help you find the information you\\'re looking for if you provide me with a search query. For example, you could ask me to search for \"weather in Bangalore\".\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-c17ed5bf-0364-4c26-854d-729c2519fdc2-0', usage_metadata={'input_tokens': 126, 'output_tokens': 48, 'total_tokens': 174, 'input_token_details': {'cache_read': 0}})]}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "# Import relevant functionality\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "# Create the agent\n",
        "memory = MemorySaver()\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0,max_tokens=None,timeout=None,max_retries=2)\n",
        "search = TavilySearchResults(max_results=2)\n",
        "tools = [search]\n",
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
        "\n",
        "# Use the agent\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"hi im Abhisek! and i live in Banglore.\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")\n",
        "\n",
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather where I live?\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mojHhkoZd9O",
        "outputId": "0a392d82-6e9b-4865-9430-513685c45aa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Bangalore', 'region': 'Karnataka', 'country': 'India', 'lat': 12.9833, 'lon': 77.5833, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1734502809, 'localtime': '2024-12-18 11:50'}, 'current': {'last_updated_epoch': 1734502500, 'last_updated': '2024-12-18 11:45', 'temp_c': 25.3, 'temp_f': 77.5, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 5.1, 'wind_kph': 8.3, 'wind_degree': 16, 'wind_dir': 'NNE', 'pressure_mb': 1016.0, 'pressure_in': 30.0, 'precip_mm': 0.04, 'precip_in': 0.0, 'humidity': 79, 'cloud': 50, 'feelslike_c': 26.7, 'feelslike_f': 80.1, 'windchill_c': 24.8, 'windchill_f': 76.7, 'heatindex_c': 26.2, 'heatindex_f': 79.2, 'dewpoint_c': 17.8, 'dewpoint_f': 64.1, 'vis_km': 6.0, 'vis_miles': 3.0, 'uv': 8.4, 'gust_mph': 5.9, 'gust_kph': 9.5}}\"}, {'url': 'https://www.hindustantimes.com/cities/bengaluru-news/bangalore-weather-today-aqi-and-rain-forecast-updates-december-18-2024-101734485407266.html', 'content': \"The temperature in Bangalore today, on December 18, 2024, is 25.7 °C. The day's forecast indicates a minimum and maximum temperature of 18.16 °C and 26.59 °C, respectively. The relative\"}]\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search = TavilySearchResults(max_results=2)\n",
        "search_results = search.invoke(\"what is the weather in Banglore.\")\n",
        "print(search_results)\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "qmw7ruOjbHSA",
        "outputId": "222a1c53-7e17-47bf-f61d-154411db2e0b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hi there! How can I help you today?\\n'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXMel59abTYJ"
      },
      "outputs": [],
      "source": [
        "model_with_tools = model.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtnFluh8bafT",
        "outputId": "608f9760-0c4e-4465-f051-d6008cf730b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ContentString: Hello! How can I help you today?\n",
            "\n",
            "ToolCalls: []\n"
          ]
        }
      ],
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LodujTfubh2H",
        "outputId": "4972c003-5925-499a-fe08-e13a62ea69e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ContentString: \n",
            "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Bangalore'}, 'id': '83b4fed4-1977-44de-816d-07ff7edb0dff', 'type': 'tool_call'}]\n"
          ]
        }
      ],
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in Banglore?\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJYcLROCgscn"
      },
      "source": [
        "#Create the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye8ww2RubnOt"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(model, tools)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLhDXGogg3FK"
      },
      "source": [
        "#Run the Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxMCQOzxb189",
        "outputId": "3c090b91-946e-42a2-cdb8-f0b72c68bec9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='48d773f2-17f2-4270-ac13-a989d26f8576'),\n",
              " AIMessage(content='Hello! How can I help you today?\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-a657684c-ba97-408e-8230-2d09786f68c7-0', usage_metadata={'input_tokens': 76, 'output_tokens': 10, 'total_tokens': 86, 'input_token_details': {'cache_read': 0}})]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
        "\n",
        "response[\"messages\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKb8wPYrcgAC",
        "outputId": "199cdfe5-ec69-42fd-a822-6cc775827b24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content='whats the weather in Banglore?', additional_kwargs={}, response_metadata={}, id='c6ded505-bae2-4293-8c1a-3df411d78586'),\n",
              " AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"weather in Bangalore\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-08f2893d-54c5-43c2-9047-9a540d3f50be-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Bangalore'}, 'id': '19a5b3fd-113e-42f5-ac0a-560a6350dd49', 'type': 'tool_call'}], usage_metadata={'input_tokens': 81, 'output_tokens': 12, 'total_tokens': 93, 'input_token_details': {'cache_read': 0}}),\n",
              " ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'Bangalore\\', \\'region\\': \\'Karnataka\\', \\'country\\': \\'India\\', \\'lat\\': 12.9833, \\'lon\\': 77.5833, \\'tz_id\\': \\'Asia/Kolkata\\', \\'localtime_epoch\\': 1734503206, \\'localtime\\': \\'2024-12-18 11:56\\'}, \\'current\\': {\\'last_updated_epoch\\': 1734502500, \\'last_updated\\': \\'2024-12-18 11:45\\', \\'temp_c\\': 25.3, \\'temp_f\\': 77.5, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 5.1, \\'wind_kph\\': 8.3, \\'wind_degree\\': 16, \\'wind_dir\\': \\'NNE\\', \\'pressure_mb\\': 1016.0, \\'pressure_in\\': 30.0, \\'precip_mm\\': 0.04, \\'precip_in\\': 0.0, \\'humidity\\': 79, \\'cloud\\': 50, \\'feelslike_c\\': 26.7, \\'feelslike_f\\': 80.1, \\'windchill_c\\': 24.8, \\'windchill_f\\': 76.7, \\'heatindex_c\\': 26.2, \\'heatindex_f\\': 79.2, \\'dewpoint_c\\': 17.8, \\'dewpoint_f\\': 64.1, \\'vis_km\\': 6.0, \\'vis_miles\\': 3.0, \\'uv\\': 8.4, \\'gust_mph\\': 5.9, \\'gust_kph\\': 9.5}}\"}, {\"url\": \"https://world-weather.info/forecast/india/bangalor/18-december/\", \"content\": \"Detailed ⚡ Weather Forecast for December 18 in Bangalore, State of Karnātaka, India - 🌡️ temperature, wind, atmospheric pressure, humidity and precipitations - World-Weather.info ... December 18, 2024 : Atmospheric conditions and temperature °F: RealFeel °F: Atmospheric ... Hourly forecast for 18.12.2023. December 18, 2022\"}]', name='tavily_search_results_json', id='45bad435-bb0e-4fe2-849a-2835d8d9fcce', tool_call_id='19a5b3fd-113e-42f5-ac0a-560a6350dd49', artifact={'query': 'weather in Bangalore', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in Bangalore', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Bangalore', 'region': 'Karnataka', 'country': 'India', 'lat': 12.9833, 'lon': 77.5833, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1734503206, 'localtime': '2024-12-18 11:56'}, 'current': {'last_updated_epoch': 1734502500, 'last_updated': '2024-12-18 11:45', 'temp_c': 25.3, 'temp_f': 77.5, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 5.1, 'wind_kph': 8.3, 'wind_degree': 16, 'wind_dir': 'NNE', 'pressure_mb': 1016.0, 'pressure_in': 30.0, 'precip_mm': 0.04, 'precip_in': 0.0, 'humidity': 79, 'cloud': 50, 'feelslike_c': 26.7, 'feelslike_f': 80.1, 'windchill_c': 24.8, 'windchill_f': 76.7, 'heatindex_c': 26.2, 'heatindex_f': 79.2, 'dewpoint_c': 17.8, 'dewpoint_f': 64.1, 'vis_km': 6.0, 'vis_miles': 3.0, 'uv': 8.4, 'gust_mph': 5.9, 'gust_kph': 9.5}}\", 'score': 0.9980975, 'raw_content': None}, {'title': 'Weather in Bangalore, December 18', 'url': 'https://world-weather.info/forecast/india/bangalor/18-december/', 'content': 'Detailed ⚡ Weather Forecast for December 18 in Bangalore, State of Karnātaka, India - 🌡️ temperature, wind, atmospheric pressure, humidity and precipitations - World-Weather.info ... December 18, 2024 : Atmospheric conditions and temperature °F: RealFeel °F: Atmospheric ... Hourly forecast for 18.12.2023. December 18, 2022', 'score': 0.9968149, 'raw_content': None}], 'response_time': 2.79}),\n",
              " AIMessage(content='The weather in Bangalore, India is partly cloudy with a temperature of 25.3°C.  The wind is blowing from the north-northeast at 8.3 kph. The humidity is 79%.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-99898901-a89d-4663-9ece-6247ca702c02-0', usage_metadata={'input_tokens': 780, 'output_tokens': 47, 'total_tokens': 827, 'input_token_details': {'cache_read': 0}})]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in Banglore?\")]}\n",
        ")\n",
        "response[\"messages\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pev11dQ6g-pH"
      },
      "source": [
        "#Streaming the Messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVYwFlNYcnAH",
        "outputId": "ac8e8e90-3c7a-4d73-8e09-ea843b1db671"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'tavily_search_results_json', 'arguments': '{\"query\": \"weather in Bangalore\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-b8fbc0bc-0c1b-4ee7-8a23-f4831d5e5709-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'weather in Bangalore'}, 'id': '26362f64-4405-4871-a3d5-5782b80581ab', 'type': 'tool_call'}], usage_metadata={'input_tokens': 81, 'output_tokens': 12, 'total_tokens': 93, 'input_token_details': {'cache_read': 0}})]}}\n",
            "----\n",
            "{'tools': {'messages': [ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'Bangalore\\', \\'region\\': \\'Karnataka\\', \\'country\\': \\'India\\', \\'lat\\': 12.9833, \\'lon\\': 77.5833, \\'tz_id\\': \\'Asia/Kolkata\\', \\'localtime_epoch\\': 1734503206, \\'localtime\\': \\'2024-12-18 11:56\\'}, \\'current\\': {\\'last_updated_epoch\\': 1734502500, \\'last_updated\\': \\'2024-12-18 11:45\\', \\'temp_c\\': 25.3, \\'temp_f\\': 77.5, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Partly cloudy\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/116.png\\', \\'code\\': 1003}, \\'wind_mph\\': 5.1, \\'wind_kph\\': 8.3, \\'wind_degree\\': 16, \\'wind_dir\\': \\'NNE\\', \\'pressure_mb\\': 1016.0, \\'pressure_in\\': 30.0, \\'precip_mm\\': 0.04, \\'precip_in\\': 0.0, \\'humidity\\': 79, \\'cloud\\': 50, \\'feelslike_c\\': 26.7, \\'feelslike_f\\': 80.1, \\'windchill_c\\': 24.8, \\'windchill_f\\': 76.7, \\'heatindex_c\\': 26.2, \\'heatindex_f\\': 79.2, \\'dewpoint_c\\': 17.8, \\'dewpoint_f\\': 64.1, \\'vis_km\\': 6.0, \\'vis_miles\\': 3.0, \\'uv\\': 8.4, \\'gust_mph\\': 5.9, \\'gust_kph\\': 9.5}}\"}, {\"url\": \"https://www.weather25.com/asia/india/karnataka/bangalore?page=month&month=December\", \"content\": \"Bangalore weather in December 2024 | Weather25.com Bangalore  Bangalore Bangalore weather in December 2024 You can expect a few rainy days in Bangalore during December, but usually the weather is comfortable in December. | Bangalore in May | | Bangalore in December | Temperatures in Bangalore in December Weather in Bangalore in December - FAQ The average temperature in Bangalore in December is 17/27° C. On average, there are 2 rainy days in Bangalore during December. Weather wise, is December a good time to visit Bangalore? The weather in Bangalore in December is perfect. On average, there are 0 snowy days in Bangalore in December. More about the weather in Bangalore\"}]', name='tavily_search_results_json', id='d470a319-ae40-4f25-95e5-ba6092f3dc3c', tool_call_id='26362f64-4405-4871-a3d5-5782b80581ab', artifact={'query': 'weather in Bangalore', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in Bangalore', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'Bangalore', 'region': 'Karnataka', 'country': 'India', 'lat': 12.9833, 'lon': 77.5833, 'tz_id': 'Asia/Kolkata', 'localtime_epoch': 1734503206, 'localtime': '2024-12-18 11:56'}, 'current': {'last_updated_epoch': 1734502500, 'last_updated': '2024-12-18 11:45', 'temp_c': 25.3, 'temp_f': 77.5, 'is_day': 1, 'condition': {'text': 'Partly cloudy', 'icon': '//cdn.weatherapi.com/weather/64x64/day/116.png', 'code': 1003}, 'wind_mph': 5.1, 'wind_kph': 8.3, 'wind_degree': 16, 'wind_dir': 'NNE', 'pressure_mb': 1016.0, 'pressure_in': 30.0, 'precip_mm': 0.04, 'precip_in': 0.0, 'humidity': 79, 'cloud': 50, 'feelslike_c': 26.7, 'feelslike_f': 80.1, 'windchill_c': 24.8, 'windchill_f': 76.7, 'heatindex_c': 26.2, 'heatindex_f': 79.2, 'dewpoint_c': 17.8, 'dewpoint_f': 64.1, 'vis_km': 6.0, 'vis_miles': 3.0, 'uv': 8.4, 'gust_mph': 5.9, 'gust_kph': 9.5}}\", 'score': 0.9935265, 'raw_content': None}, {'title': 'Bangalore weather in December 2024 | Weather25.com', 'url': 'https://www.weather25.com/asia/india/karnataka/bangalore?page=month&month=December', 'content': 'Bangalore weather in December 2024 | Weather25.com Bangalore  Bangalore Bangalore weather in December 2024 You can expect a few rainy days in Bangalore during December, but usually the weather is comfortable in December. | Bangalore in May | | Bangalore in December | Temperatures in Bangalore in December Weather in Bangalore in December - FAQ The average temperature in Bangalore in December is 17/27° C. On average, there are 2 rainy days in Bangalore during December. Weather wise, is December a good time to visit Bangalore? The weather in Bangalore in December is perfect. On average, there are 0 snowy days in Bangalore in December. More about the weather in Bangalore', 'score': 0.9927672, 'raw_content': None}], 'response_time': 2.65})]}}\n",
            "----\n",
            "{'agent': {'messages': [AIMessage(content='The weather in Bangalore is partly cloudy with a temperature of 25.3°C. The wind is blowing from the NNE at 8.3 kph.  The humidity is 79%.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-fafb2368-8da6-43e6-ad3d-412b012b6e95-0', usage_metadata={'input_tokens': 838, 'output_tokens': 44, 'total_tokens': 882, 'input_token_details': {'cache_read': 0}})]}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in Banglore?\")]}\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFBw3gxzhFwS"
      },
      "source": [
        "#Streaming tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a78aCQfdIeC",
        "outputId": "be0b4b8d-327f-4432-c7a6-061f5e05f37f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--\n",
            "Starting tool: tavily_search_results_json with inputs: {'query': 'weather in san francisco'}\n",
            "Done tool: tavily_search_results_json\n",
            "Tool output was: content='[{\"url\": \"https://www.wunderground.com/weather/us/ca/san-francisco\", \"content\": \"San Francisco, CA Weather Conditions | Weather Underground San Francisco, CA Weather Conditions_star_rate__home_ 56\\xa0°F South of Market Station|Report Report Station You are about to report this weather station for bad data. Personal Weather Station Nearby Weather Stations Nearby Weather Stations The time period when the sun is no more than 6 degrees below the horizon at either sunrise or sunset. The time period when the sun is between 6 and 12 degrees below the horizon at either sunrise or sunset. The time period when the sun is between 12 and 18 degrees below the horizon at either sunrise or sunset. The sun does not contribute to the illumination of the sky before this time in the morning, or after this time in the evening.\"}, {\"url\": \"https://www.accuweather.com/en/us/san-francisco/94103/weather-forecast/347629\", \"content\": \"San Francisco, CA Weather Forecast | AccuWeather Winter Weather Storm with wind, snow and some rain brewing for Midwest, East 7 hours ago Hurricane Sara moves into Gulf, set to bring heavy rain to South, Southeast 4 hours ago Astronomy Moon to align with Jupiter, Mars on Monday night 4 hours ago Severe Weather Severe thunderstorms to rumble through southern Plains on Monday 2 hours ago Winter Weather More storms with rain, mountain snow lining up for northwestern US 7 hours ago  More Stories AccuWeather Ready Business Health Hurricane Leisure and Recreation Severe Weather Space and Astronomy Sports Travel Weather News Winter Center AccuWeather Ready Business Health Hurricane Leisure and Recreation Severe Weather Space and Astronomy Sports Travel Weather News Winter Center\"}]' name='tavily_search_results_json' tool_call_id='87adcceb-fd38-43b9-8887-ab38f9eb5f44' artifact={'query': 'weather in san francisco', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'San Francisco, CA Weather Conditions | Weather Underground', 'url': 'https://www.wunderground.com/weather/us/ca/san-francisco', 'content': 'San Francisco, CA Weather Conditions | Weather Underground San Francisco, CA Weather Conditions_star_rate__home_ 56\\xa0°F South of Market Station|Report Report Station You are about to report this weather station for bad data. Personal Weather Station Nearby Weather Stations Nearby Weather Stations The time period when the sun is no more than 6 degrees below the horizon at either sunrise or sunset. The time period when the sun is between 6 and 12 degrees below the horizon at either sunrise or sunset. The time period when the sun is between 12 and 18 degrees below the horizon at either sunrise or sunset. The sun does not contribute to the illumination of the sky before this time in the morning, or after this time in the evening.', 'score': 0.99722075, 'raw_content': None}, {'title': 'San Francisco, CA Weather Forecast | AccuWeather', 'url': 'https://www.accuweather.com/en/us/san-francisco/94103/weather-forecast/347629', 'content': 'San Francisco, CA Weather Forecast | AccuWeather Winter Weather Storm with wind, snow and some rain brewing for Midwest, East 7 hours ago Hurricane Sara moves into Gulf, set to bring heavy rain to South, Southeast 4 hours ago Astronomy Moon to align with Jupiter, Mars on Monday night 4 hours ago Severe Weather Severe thunderstorms to rumble through southern Plains on Monday 2 hours ago Winter Weather More storms with rain, mountain snow lining up for northwestern US 7 hours ago  More Stories AccuWeather Ready Business Health Hurricane Leisure and Recreation Severe Weather Space and Astronomy Sports Travel Weather News Winter Center AccuWeather Ready Business Health Hurricane Leisure and Recreation Severe Weather Space and Astronomy Sports Travel Weather News Winter Center', 'score': 0.989791, 'raw_content': None}], 'response_time': 3.04}\n",
            "--\n",
            "The| weather in San Francisco is currently 56°F.  It is expected| to have some rain and mountain snow.  A winter storm is brewing for the| midwest and east.\n",
            "|"
          ]
        }
      ],
      "source": [
        "async for event in agent_executor.astream_events(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}, version=\"v1\"\n",
        "):\n",
        "    kind = event[\"event\"]\n",
        "    if kind == \"on_chain_start\":\n",
        "        if (\n",
        "            event[\"name\"] == \"Agent\"\n",
        "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "            print(\n",
        "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
        "            )\n",
        "    elif kind == \"on_chain_end\":\n",
        "        if (\n",
        "            event[\"name\"] == \"Agent\"\n",
        "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "            print()\n",
        "            print(\"--\")\n",
        "            print(\n",
        "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
        "            )\n",
        "    if kind == \"on_chat_model_stream\":\n",
        "        content = event[\"data\"][\"chunk\"].content\n",
        "        if content:\n",
        "            # Empty content in the context of OpenAI means\n",
        "            # that the model is asking for a tool to be invoked.\n",
        "            # So we only print non-empty content\n",
        "            print(content, end=\"|\")\n",
        "    elif kind == \"on_tool_start\":\n",
        "        print(\"--\")\n",
        "        print(\n",
        "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
        "        )\n",
        "    elif kind == \"on_tool_end\":\n",
        "        print(f\"Done tool: {event['name']}\")\n",
        "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
        "        print(\"--\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPUMTAJdhLRv"
      },
      "source": [
        "#Adding the memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwegz3-1fcZB"
      },
      "outputs": [],
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()\n",
        "\n",
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Vlh94DMhX2y",
        "outputId": "e3584fde-86c7-494a-b8f6-eb5bf3f56288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content='Hello Abhisek! How can I help you today?\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e61064e6-5e72-4f11-a308-eeea7ceac6f3-0', usage_metadata={'input_tokens': 96, 'output_tokens': 12, 'total_tokens': 108, 'input_token_details': {'cache_read': 0}})]}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"hi im Abhisek!\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-v-0184hZo2",
        "outputId": "6c8a08bb-313b-4cc9-8bc2-b4feefcb5fea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content='You told me your name is Abhisek.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-35775ec5-46fd-47b4-930a-a358f409a1d3-0', usage_metadata={'input_tokens': 114, 'output_tokens': 10, 'total_tokens': 124, 'input_token_details': {'cache_read': 0}})]}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsCvu3a1hkIT",
        "outputId": "775c0977-f1c4-44c5-bcb7-13642c306842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'agent': {'messages': [AIMessage(content=\"I don’t have access to that information. I'm a large language model, able to communicate in response to a wide range of prompts and questions, but my knowledge about your name is limited. Is there anything else I can do to help?\\n\\n\\n\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-f274f9ee-9c6a-41db-8aad-82613af52977-0', usage_metadata={'input_tokens': 136, 'output_tokens': 52, 'total_tokens': 188, 'input_token_details': {'cache_read': 0}})]}}\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"xyz123\"}}\n",
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHc3LUIhrrGK"
      },
      "source": [
        "#ChromaDB (Vector Stores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhr3168QbpKG"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNpA3Ywjbz4U"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"example_collection\",\n",
        "    embedding_function=embeddings,\n",
        "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LA9h0oWwe-vh"
      },
      "source": [
        "Initialize the Client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujo8_1YpcGDd",
        "outputId": "78e19f81-e844-4438-d0c9-6e9a595974a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/root/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:07<00:00, 10.5MiB/s]\n"
          ]
        }
      ],
      "source": [
        "import chromadb\n",
        "\n",
        "persistent_client = chromadb.PersistentClient()\n",
        "collection = persistent_client.get_or_create_collection(\"collection_name\")\n",
        "collection.add(ids=[\"1\", \"2\", \"3\"], documents=[\"a\", \"b\", \"c\"])\n",
        "\n",
        "vector_store_from_client = Chroma(\n",
        "    client=persistent_client,\n",
        "    collection_name=\"collection_name\",\n",
        "    embedding_function=embeddings,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgVQUDwDffPu"
      },
      "source": [
        "#Manage Vector Store\n",
        "\n",
        "Add item to vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9t7iGRT_fEW7",
        "outputId": "fe0e9e81-fea7-4145-dc07-4a62a8b2acf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['bfe9e60a-c6c9-411f-ba76-d1749ba3f9bd',\n",
              " '36be785b-0298-4335-a780-b54264d11f84',\n",
              " '99a4643a-2d53-413e-9c6a-3c04ea68e8b8',\n",
              " '94e05a09-5445-47d9-a124-0c3c317422d8',\n",
              " '5018f573-673f-44a6-9e36-73db705ae406',\n",
              " 'c9fc1a93-ed31-4faa-9446-7a47c3aed08b',\n",
              " '40377963-8e6d-4b33-8120-4b294f4e3054',\n",
              " '624aec41-bf82-4c3e-ae49-4e996959c8a6',\n",
              " '4d73ebd1-14f9-4518-b00d-a10dd9521173',\n",
              " 'a893a6ba-1352-441e-81f4-b0fa39a85f75']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=1,\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=2,\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=3,\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=4,\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=5,\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        "    id=6,\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        "    id=7,\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=8,\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=9,\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=10,\n",
        ")\n",
        "\n",
        "documents = [\n",
        "    document_1,\n",
        "    document_2,\n",
        "    document_3,\n",
        "    document_4,\n",
        "    document_5,\n",
        "    document_6,\n",
        "    document_7,\n",
        "    document_8,\n",
        "    document_9,\n",
        "    document_10,\n",
        "]\n",
        "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
        "\n",
        "vector_store.add_documents(documents=documents, ids=uuids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOV2btrJf8G_"
      },
      "source": [
        "Update items in vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rINA3td9fzMm"
      },
      "outputs": [],
      "source": [
        "updated_document_1 = Document(\n",
        "    page_content=\"I had chocolate chip pancakes and fried eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "    id=1,\n",
        ")\n",
        "\n",
        "updated_document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is sunny and warm, with a high of 82 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "    id=2,\n",
        ")\n",
        "\n",
        "# Updating one document\n",
        "vector_store.update_document(document_id=uuids[0], document=updated_document_1)\n",
        "\n",
        "\n",
        "# Updating multiple documents at once\n",
        "vector_store.update_documents(\n",
        "    ids=uuids[:2], documents=[updated_document_1, updated_document_2]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbG1Z-IFhKUW"
      },
      "source": [
        "Deleting an item in vector store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgFkSLh1gQb-"
      },
      "outputs": [],
      "source": [
        "vector_store.delete(ids=uuids[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cTHPzO2hRGj"
      },
      "source": [
        "#Query Vector Store\n",
        "\n",
        "Query directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-js9_laNhOj3",
        "outputId": "6ecb2ff4-75fa-4834-ac75-6981ae7b55d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
            "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
          ]
        }
      ],
      "source": [
        "# Similarity search\n",
        "\n",
        "results = vector_store.similarity_search(\n",
        "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
        "    k=2,\n",
        "    filter={\"source\": \"tweet\"},\n",
        ")\n",
        "for res in results:\n",
        "    print(f\"* {res.page_content} [{res.metadata}]\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msCZ2niJhyoB",
        "outputId": "abe34d7d-fa83-4ff0-cdfa-175e3d462e11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* [SIM=0.753576] The weather forecast for tomorrow is sunny and warm, with a high of 82 degrees. [{'source': 'news'}]\n"
          ]
        }
      ],
      "source": [
        "# similarity search with score\n",
        "\n",
        "results = vector_store.similarity_search_with_score(\n",
        "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
        ")\n",
        "for res, score in results:\n",
        "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qa3V5NLh90W",
        "outputId": "5b782c09-b66d-4cc3-8611-8d897d00959d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* I had chocolate chip pancakes and fried eggs for breakfast this morning. [{'source': 'tweet'}]\n"
          ]
        }
      ],
      "source": [
        "# similarity search with vector\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(\n",
        "    embedding=embeddings.embed_query(\"I love green eggs and ham!\"), k=1\n",
        ")\n",
        "for doc in results:\n",
        "    print(f\"* {doc.page_content} [{doc.metadata}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_O7FgtgiLUm"
      },
      "source": [
        "Query by turning into retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Tss56VJiKWd",
        "outputId": "303daff3-dfa6-4e82-c159-598771eae23e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.')]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"mmr\", search_kwargs={\"k\": 1, \"fetch_k\": 5}\n",
        ")\n",
        "retriever.invoke(\"Stealing from the bank is a crime\", filter={\"source\": \"news\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHpZJh4mrk2b"
      },
      "source": [
        "#Build a semantic search engine\n",
        "\n",
        "Documents and Document Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOvTdv3gio3M"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "\n",
        "# Making our own document which consists of page_content, metadata and id.\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\"Dogs are great companions, known for their loyalty and friendliness.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Cats are independent pets that often enjoy their own space.\",\n",
        "        metadata={\"source\": \"mammal-pets-doc\"},\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D16_XmFgs_VG",
        "outputId": "72a1c1a1-d322-47df-b373-72bdb2eecfd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "108\n"
          ]
        }
      ],
      "source": [
        "# loading a pdf\n",
        "\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = \"/content/who_will_cry_when_you_die.pdf\"\n",
        "loader = PyPDFLoader(file_path)\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1bE65K6tr0F",
        "outputId": "fc672a0d-ca13-4c46-ccfd-f5190416a085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24. Learn from a Good Movie \n",
            "25. Bless Your Money \n",
            "26. Focus on the Worthy \n",
            "27. Write Thank – You Notes \n",
            "28. Always Carry a Book with You \n",
            "29. Create a Love Account \n",
            "30. Get Behind People’s Eyeballs \n",
            "\n",
            "\n",
            "{'source': '/content/who_will_cry_when_you_die.pdf', 'page': 1}\n"
          ]
        }
      ],
      "source": [
        "print(f\"{docs[1].page_content[:200]}\\n\")\n",
        "print(docs[1].metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fx_N_1YZuCZZ",
        "outputId": "155af75f-afd9-43f0-cb95-7f9b54f291a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "271"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
        ")\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "len(all_splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmiKxZXuv-5s"
      },
      "source": [
        "Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXSyKumvvhS5"
      },
      "outputs": [],
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W9A-KPlwpDu",
        "outputId": "a73d57e7-8fb8-494f-8506-5ddb128f065d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated vectors of length 768 768\n",
            "\n",
            "[0.06311293691396713, 0.09207168221473694, 0.0022925566881895065, -0.04413921386003494, 0.02232925035059452, -0.021049587056040764, -0.05254006013274193, -0.014108899980783463, 0.03661872819066048, 0.06399504840373993]\n"
          ]
        }
      ],
      "source": [
        "vector_1 = embeddings.embed_query(all_splits[0].page_content)\n",
        "vector_2 = embeddings.embed_query(all_splits[1].page_content)\n",
        "\n",
        "assert len(vector_1) == len(vector_2)\n",
        "print(f\"Generated vectors of length {len(vector_1)} {len(vector_2)}\\n\")\n",
        "print(vector_1[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1Ai0fp8yoT2"
      },
      "source": [
        "Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0d4HuMvtxREy"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "vector_store = Chroma(embedding_function=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5qB3RuvytJ3"
      },
      "outputs": [],
      "source": [
        "ids = vector_store.add_documents(documents=all_splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NR5NCD7YywjC",
        "outputId": "6924c11c-1a7d-451d-a5a9-d5f54ae907a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='and doing what you can to enrich the world around you? In my mind, if you make even one person smile \n",
            "during your day or brighten the mood of even one stranger, your day has been a worthwhile one. Kindness, \n",
            "quite simply, is the tent we must pay for the space we occupy on this planet. \n",
            " Become more creative in the ways you show compa ssion to strangers. Paying the toll for the person in \n",
            "the car behind you, offering your seat on the subway to someone in need and being the first to say hello are \n",
            "great places to start. Recently, I received a letter from a reader of The Monk Who Sold His Ferrari who lives \n",
            "in Washington State. In it she wrote: “I have a practice of tithing to people who have helped me along my \n",
            "spiritual path. Please accept the enclosed check of $ 100 with my blessing and gratitude.” I quickly \n",
            "responded to her generous act by spending one of my audiotape programs in return so she received value for' metadata={'page': 5, 'source': '/content/who_will_cry_when_you_die.pdf', 'start_index': 899}\n"
          ]
        }
      ],
      "source": [
        "# Return documents based on similarity to a string query:\n",
        "\n",
        "results = vector_store.similarity_search(\n",
        "    \"Why we have to be kind to a stranger everyday?\"\n",
        ")\n",
        "\n",
        "print(results[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vQXXEvY0OXG",
        "outputId": "07f7de95-24e6-49ce-8a1b-31cd28a900b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='and doing what you can to enrich the world around you? In my mind, if you make even one person smile \n",
            "during your day or brighten the mood of even one stranger, your day has been a worthwhile one. Kindness, \n",
            "quite simply, is the tent we must pay for the space we occupy on this planet. \n",
            " Become more creative in the ways you show compa ssion to strangers. Paying the toll for the person in \n",
            "the car behind you, offering your seat on the subway to someone in need and being the first to say hello are \n",
            "great places to start. Recently, I received a letter from a reader of The Monk Who Sold His Ferrari who lives \n",
            "in Washington State. In it she wrote: “I have a practice of tithing to people who have helped me along my \n",
            "spiritual path. Please accept the enclosed check of $ 100 with my blessing and gratitude.” I quickly \n",
            "responded to her generous act by spending one of my audiotape programs in return so she received value for' metadata={'page': 5, 'source': '/content/who_will_cry_when_you_die.pdf', 'start_index': 899}\n"
          ]
        }
      ],
      "source": [
        "# async query:\n",
        "\n",
        "results = await vector_store.asimilarity_search(\"Why we have to be kind to a stranger everyday?\")\n",
        "\n",
        "print(results[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A14bi7ny1-zT",
        "outputId": "742cec31-0bfc-42cb-9a3e-74a9708541fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score: 0.9550238847732544\n",
            "\n",
            "page_content='7. \n",
            "Honor Your Past  \n",
            "Every second you dwell on the past you steal from your future. Every minute you spend focusing on your \n",
            "problems you take away from finding your solutions. And thinking about all those things that you wish never \n",
            "happened to you is actually blocking all the things you want to happen from entering into your life. Given the \n",
            "timeless truth that hold that you become what you think about all day long, it makes no sense to worry about \n",
            "past events or mistakes unless you want to experience them for a second time. Instead, use the lessons you have \n",
            "learned from your past to rise to a whole new level of awareness and enlightenment. \n",
            " Life’s greatest setbacks reveal life’s biggest opportunities. As the ancient thinker Euripides noted,  \n",
            "“There is in the worst of fortune the best chances for a happy change.” If you have suffered more than your fair \n",
            "share of difficulties in life, perhaps you are being prepared to serve some greater purpose that will require you' metadata={'page': 10, 'source': '/content/who_will_cry_when_you_die.pdf', 'start_index': 2}\n"
          ]
        }
      ],
      "source": [
        "# Return scores:\n",
        "\n",
        "# Note that providers implement different scores; the score here\n",
        "# is a distance metric that varies inversely with similarity.\n",
        "\n",
        "results = vector_store.similarity_search_with_score(\"Why we have to honor our past?\")\n",
        "doc, score = results[0]\n",
        "print(f\"Score: {score}\\n\")\n",
        "print(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2yfkkvd2WlW",
        "outputId": "fbe10fad-c5df-4c89-81f0-4d8432ee7f69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='and doing what you can to enrich the world around you? In my mind, if you make even one person smile \n",
            "during your day or brighten the mood of even one stranger, your day has been a worthwhile one. Kindness, \n",
            "quite simply, is the tent we must pay for the space we occupy on this planet. \n",
            " Become more creative in the ways you show compa ssion to strangers. Paying the toll for the person in \n",
            "the car behind you, offering your seat on the subway to someone in need and being the first to say hello are \n",
            "great places to start. Recently, I received a letter from a reader of The Monk Who Sold His Ferrari who lives \n",
            "in Washington State. In it she wrote: “I have a practice of tithing to people who have helped me along my \n",
            "spiritual path. Please accept the enclosed check of $ 100 with my blessing and gratitude.” I quickly \n",
            "responded to her generous act by spending one of my audiotape programs in return so she received value for' metadata={'page': 5, 'source': '/content/who_will_cry_when_you_die.pdf', 'start_index': 899}\n"
          ]
        }
      ],
      "source": [
        "embedding = embeddings.embed_query(\"Why we have to be kind to a stranger everyday?\")\n",
        "\n",
        "results = vector_store.similarity_search_by_vector(embedding)\n",
        "print(results[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av4h-dCQ-54q"
      },
      "source": [
        "Retrievers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeYNcU0e4qaX",
        "outputId": "972e26bc-9b95-4203-a3aa-65085163d4c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[Document(metadata={'page': 5, 'source': '/content/who_will_cry_when_you_die.pdf', 'start_index': 899}, page_content='and doing what you can to enrich the world around you? In my mind, if you make even one person smile \\nduring your day or brighten the mood of even one stranger, your day has been a worthwhile one. Kindness, \\nquite simply, is the tent we must pay for the space we occupy on this planet. \\n Become more creative in the ways you show compa ssion to strangers. Paying the toll for the person in \\nthe car behind you, offering your seat on the subway to someone in need and being the first to say hello are \\ngreat places to start. Recently, I received a letter from a reader of The Monk Who Sold His Ferrari who lives \\nin Washington State. In it she wrote: “I have a practice of tithing to people who have helped me along my \\nspiritual path. Please accept the enclosed check of $ 100 with my blessing and gratitude.” I quickly \\nresponded to her generous act by spending one of my audiotape programs in return so she received value for')],\n",
              " [Document(metadata={'page': 10, 'source': '/content/who_will_cry_when_you_die.pdf', 'start_index': 2}, page_content='7. \\nHonor Your Past  \\nEvery second you dwell on the past you steal from your future. Every minute you spend focusing on your \\nproblems you take away from finding your solutions. And thinking about all those things that you wish never \\nhappened to you is actually blocking all the things you want to happen from entering into your life. Given the \\ntimeless truth that hold that you become what you think about all day long, it makes no sense to worry about \\npast events or mistakes unless you want to experience them for a second time. Instead, use the lessons you have \\nlearned from your past to rise to a whole new level of awareness and enlightenment. \\n Life’s greatest setbacks reveal life’s biggest opportunities. As the ancient thinker Euripides noted,  \\n“There is in the worst of fortune the best chances for a happy change.” If you have suffered more than your fair \\nshare of difficulties in life, perhaps you are being prepared to serve some greater purpose that will require you')]]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import List\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import chain\n",
        "\n",
        "\n",
        "@chain\n",
        "def retriever(query: str) -> List[Document]:\n",
        "    return vector_store.similarity_search(query, k=1)\n",
        "\n",
        "\n",
        "retriever.batch(\n",
        "    [\n",
        "        \"Why we have to be kind to a stranger everyday?\",\n",
        "        \"Why we have to honor our past?\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn2s42WiRkIS",
        "outputId": "204040a1-d2db-4192-bee4-6c6119338703"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[Document(metadata={'page': 5, 'source': '/content/who_will_cry_when_you_die.pdf', 'start_index': 899}, page_content='and doing what you can to enrich the world around you? In my mind, if you make even one person smile \\nduring your day or brighten the mood of even one stranger, your day has been a worthwhile one. Kindness, \\nquite simply, is the tent we must pay for the space we occupy on this planet. \\n Become more creative in the ways you show compa ssion to strangers. Paying the toll for the person in \\nthe car behind you, offering your seat on the subway to someone in need and being the first to say hello are \\ngreat places to start. Recently, I received a letter from a reader of The Monk Who Sold His Ferrari who lives \\nin Washington State. In it she wrote: “I have a practice of tithing to people who have helped me along my \\nspiritual path. Please accept the enclosed check of $ 100 with my blessing and gratitude.” I quickly \\nresponded to her generous act by spending one of my audiotape programs in return so she received value for')],\n",
              " [Document(metadata={'page': 10, 'source': '/content/who_will_cry_when_you_die.pdf', 'start_index': 2}, page_content='7. \\nHonor Your Past  \\nEvery second you dwell on the past you steal from your future. Every minute you spend focusing on your \\nproblems you take away from finding your solutions. And thinking about all those things that you wish never \\nhappened to you is actually blocking all the things you want to happen from entering into your life. Given the \\ntimeless truth that hold that you become what you think about all day long, it makes no sense to worry about \\npast events or mistakes unless you want to experience them for a second time. Instead, use the lessons you have \\nlearned from your past to rise to a whole new level of awareness and enlightenment. \\n Life’s greatest setbacks reveal life’s biggest opportunities. As the ancient thinker Euripides noted,  \\n“There is in the worst of fortune the best chances for a happy change.” If you have suffered more than your fair \\nshare of difficulties in life, perhaps you are being prepared to serve some greater purpose that will require you')]]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retriever = vector_store.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 1},\n",
        ")\n",
        "\n",
        "retriever.batch(\n",
        "    [\n",
        "        \"Why we have to be kind to a stranger everyday?\",\n",
        "        \"Why we have to honor our past?\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dq-PQaqnSgUW"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "tagging_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "Extract the desired information from the following passage.\n",
        "\n",
        "Only extract the properties mentioned in the 'Classification' function.\n",
        "\n",
        "Passage:\n",
        "{input}\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(description=\"The sentiment of the text\")\n",
        "    aggressiveness: int = Field(description=\"How aggressive the text is on a scale from 1 to 10\")\n",
        "    language: str = Field(description=\"The language the text is written in\")\n",
        "\n",
        "\n",
        "# LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0,max_tokens=None,timeout=None,max_retries=2).with_structured_output(Classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLAHqp9fVzv-",
        "outputId": "38e82c94-010a-4212-b4fa-7e67204e9b6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Classification(sentiment='Negative', aggressiveness=7, language='English')"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp = \"I hate this movie. i don't want to watch this movie again.\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "response = llm.invoke(prompt)\n",
        "# if we only want the output\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIlLIqDNWSVU",
        "outputId": "6aa4079b-f10e-4d7a-818b-427dee4da1d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sentiment': 'Negative', 'aggressiveness': 7, 'language': 'English'}"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# if we want the output in dict format\n",
        "response.model_dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjky_D4WXS9O"
      },
      "source": [
        "Finer control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cG9pOaRoWvjL"
      },
      "outputs": [],
      "source": [
        "class Classification(BaseModel):\n",
        "    sentiment: str = Field(description=\"The sentiment of the text, happy,neutral or sad\")\n",
        "    aggressiveness: int = Field(\n",
        "\n",
        "        description=\"describes how aggressive the statement is between 1 to 5, the higher the number the more aggressive\",\n",
        "\n",
        "    )\n",
        "    language: str = Field(\n",
        "        description=\"The language the text is written in\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z23pnZ8AYA9W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghORo3AqYMCk"
      },
      "outputs": [],
      "source": [
        "tagging_prompt = ChatPromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "Extract the desired information from the following passage.\n",
        "\n",
        "Only extract the properties mentioned in the 'Classification' function.\n",
        "\n",
        "Passage:\n",
        "{input}\n",
        "\"\"\"\n",
        ")\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0,max_tokens=None,timeout=None,max_retries=2).with_structured_output(Classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK3GXxxzZC_g",
        "outputId": "ad8f116b-0a5d-41e2-9cf3-83b57da19680"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'sentiment': 'sad', 'aggressiveness': 3, 'language': 'english'}"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inp = \"I hate this movie. i don't want to watch this movie again.\"\n",
        "prompt = tagging_prompt.invoke({\"input\": inp})\n",
        "response = llm.invoke(prompt)\n",
        "\n",
        "response.model_dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7d_uLe0fyGb"
      },
      "source": [
        "#Build an Extraction Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8xobbUTeMkA"
      },
      "outputs": [],
      "source": [
        "from typing import Optional\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Information about a person.\"\"\"\n",
        "\n",
        "    # ^ Doc-string for the entity Person.\n",
        "    # This doc-string is sent to the LLM as the description of the schema Person,\n",
        "    # and it can help to improve extraction results.\n",
        "\n",
        "    # Note that:\n",
        "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
        "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
        "    # Having a good description can help improve extraction results.\n",
        "    name: Optional[str] = Field(default=None, description=\"The name of the person\")\n",
        "    hair_color: Optional[str] = Field(\n",
        "        default=None, description=\"The color of the person's hair if known\"\n",
        "    )\n",
        "    height_in_meters: Optional[str] = Field(\n",
        "        default=None, description=\"Height measured in meters\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1RrWlGRnaI4"
      },
      "source": [
        "#Text summerization using RAG and langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgVKFdomYIKW"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/NIPS-2017-attention-is-all-you-need-Paper.pdf\")\n",
        "docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVGGtvMBfTYc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['NVIDIA_API_KEY']=\"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9MqLU8El6ua"
      },
      "outputs": [],
      "source": [
        "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
        "\n",
        "llm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaLxNWXIm43W"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define prompt\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", \"Write a detailed summary of the following:\\\\n\\\\n{context}\")]\n",
        ")\n",
        "\n",
        "# Instantiate chain\n",
        "chain = create_stuff_documents_chain(llm, prompt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "pAMApaX4owJg",
        "outputId": "66aef4c8-2864-44f7-8eed-f9f95a477e8c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "[400] Bad Request\nThis model's maximum context length is 8192 tokens. However, you requested 9273 tokens (8249 in the messages, 1024 in the completion). Please reduce the length of the messages or completion.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-cf9988c01d7e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Invoke chain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5352\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5353\u001b[0m     ) -> Output:\n\u001b[0;32m-> 5354\u001b[0;31m         return self.bound.invoke(\n\u001b[0m\u001b[1;32m   5355\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5356\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/runnables/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m         \u001b[0;31m# finish the root run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m         return cast(\n\u001b[1;32m    285\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    287\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    784\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    785\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m         flattened_outputs = [\n\u001b[1;32m    645\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 results.append(\n\u001b[0;32m--> 633\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    634\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    852\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_for_vlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_req\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra_headers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mresponses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_callback_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/_common.py\u001b[0m in \u001b[0;36mget_req\u001b[0;34m(self, payload, extra_headers)\u001b[0m\n\u001b[1;32m    471\u001b[0m     ) -> Response:\n\u001b[1;32m    472\u001b[0m         \u001b[0;34m\"\"\"Post to the API.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         response, session = self._post(\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/_common.py\u001b[0m in \u001b[0;36m_post\u001b[0;34m(self, invoke_url, payload, extra_headers)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__add_authorization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         )\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/_common.py\u001b[0m in \u001b[0;36m_try_raise\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    460\u001b[0m                 \u001b[0mbody\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\nPlease check or regenerate your API key.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0;31m# todo: raise as an HTTPError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{header}\\n{body}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;31m###################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: [400] Bad Request\nThis model's maximum context length is 8192 tokens. However, you requested 9273 tokens (8249 in the messages, 1024 in the completion). Please reduce the length of the messages or completion."
          ]
        }
      ],
      "source": [
        "# Invoke chain\n",
        "result = chain.invoke({\"context\": docs})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elnpTrhFnSEt",
        "outputId": "fac20f29-0c4e-4554-96a7-b08cb64e0818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 11 documents.\n"
          ]
        }
      ],
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=5000, chunk_overlap=0\n",
        ")\n",
        "split_docs = text_splitter.split_documents(docs)\n",
        "print(f\"Generated {len(split_docs)} documents.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQIWx9MUrKN3"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "\n",
        "map_prompt = hub.pull(\"rlm/map-prompt\")\n",
        "\n",
        "# Also available via the hub: `hub.pull(\"rlm/reduce-prompt\")`\n",
        "reduce_template = \"\"\"\n",
        "The following is a set of summaries:\n",
        "{docs}\n",
        "Take these and distill it into a final, detailed summary\n",
        "of the main themes.\n",
        "\"\"\"\n",
        "\n",
        "reduce_prompt = ChatPromptTemplate([(\"human\", reduce_template)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiWpBxzBoyki"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import Annotated, List, Literal, TypedDict\n",
        "\n",
        "from langchain.chains.combine_documents.reduce import (\n",
        "    acollapse_docs,\n",
        "    split_list_of_docs,\n",
        ")\n",
        "from langchain_core.documents import Document\n",
        "from langgraph.constants import Send\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "\n",
        "token_max = 5000\n",
        "\n",
        "\n",
        "def length_function(documents: List[Document]) -> int:\n",
        "    \"\"\"Get number of tokens for input contents.\"\"\"\n",
        "    return sum(llm.get_num_tokens(doc.page_content) for doc in documents)\n",
        "\n",
        "\n",
        "# This will be the overall state of the main graph.\n",
        "# It will contain the input document contents, corresponding\n",
        "# summaries, and a final summary.\n",
        "class OverallState(TypedDict):\n",
        "    # Notice here we use the operator.add\n",
        "    # This is because we want combine all the summaries we generate\n",
        "    # from individual nodes back into one list - this is essentially\n",
        "    # the \"reduce\" part\n",
        "    contents: List[str]\n",
        "    summaries: Annotated[list, operator.add]\n",
        "    collapsed_summaries: List[Document]\n",
        "    final_summary: str\n",
        "\n",
        "\n",
        "# This will be the state of the node that we will \"map\" all\n",
        "# documents to in order to generate summaries\n",
        "class SummaryState(TypedDict):\n",
        "    content: str\n",
        "\n",
        "\n",
        "# Here we generate a summary, given a document\n",
        "async def generate_summary(state: SummaryState):\n",
        "    prompt = map_prompt.invoke(state[\"content\"])\n",
        "    response = await llm.ainvoke(prompt)\n",
        "    return {\"summaries\": [response.content]}\n",
        "\n",
        "\n",
        "# Here we define the logic to map out over the documents\n",
        "# We will use this an edge in the graph\n",
        "def map_summaries(state: OverallState):\n",
        "    # We will return a list of `Send` objects\n",
        "    # Each `Send` object consists of the name of a node in the graph\n",
        "    # as well as the state to send to that node\n",
        "    return [\n",
        "        Send(\"generate_summary\", {\"content\": content}) for content in state[\"contents\"]\n",
        "    ]\n",
        "\n",
        "\n",
        "def collect_summaries(state: OverallState):\n",
        "    return {\n",
        "        \"collapsed_summaries\": [Document(summary) for summary in state[\"summaries\"]]\n",
        "    }\n",
        "\n",
        "\n",
        "async def _reduce(input: dict) -> str:\n",
        "    prompt = reduce_prompt.invoke(input)\n",
        "    response = await llm.ainvoke(prompt)\n",
        "    return response.content\n",
        "\n",
        "\n",
        "# Add node to collapse summaries\n",
        "async def collapse_summaries(state: OverallState):\n",
        "    doc_lists = split_list_of_docs(\n",
        "        state[\"collapsed_summaries\"], length_function, token_max\n",
        "    )\n",
        "    results = []\n",
        "    for doc_list in doc_lists:\n",
        "        results.append(await acollapse_docs(doc_list, _reduce))\n",
        "\n",
        "    return {\"collapsed_summaries\": results}\n",
        "\n",
        "\n",
        "# This represents a conditional edge in the graph that determines\n",
        "# if we should collapse the summaries or not\n",
        "def should_collapse(\n",
        "    state: OverallState,\n",
        ") -> Literal[\"collapse_summaries\", \"generate_final_summary\"]:\n",
        "    num_tokens = length_function(state[\"collapsed_summaries\"])\n",
        "    if num_tokens > token_max:\n",
        "        return \"collapse_summaries\"\n",
        "    else:\n",
        "        return \"generate_final_summary\"\n",
        "\n",
        "\n",
        "# Here we will generate the final summary\n",
        "async def generate_final_summary(state: OverallState):\n",
        "    response = await _reduce(state[\"collapsed_summaries\"])\n",
        "    return {\"final_summary\": response}\n",
        "\n",
        "\n",
        "# Construct the graph\n",
        "# Nodes:\n",
        "graph = StateGraph(OverallState)\n",
        "graph.add_node(\"generate_summary\", generate_summary)  # same as before\n",
        "graph.add_node(\"collect_summaries\", collect_summaries)\n",
        "graph.add_node(\"collapse_summaries\", collapse_summaries)\n",
        "graph.add_node(\"generate_final_summary\", generate_final_summary)\n",
        "\n",
        "# Edges:\n",
        "graph.add_conditional_edges(START, map_summaries, [\"generate_summary\"])\n",
        "graph.add_edge(\"generate_summary\", \"collect_summaries\")\n",
        "graph.add_conditional_edges(\"collect_summaries\", should_collapse)\n",
        "graph.add_conditional_edges(\"collapse_summaries\", should_collapse)\n",
        "graph.add_edge(\"generate_final_summary\", END)\n",
        "\n",
        "app = graph.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "id": "ZL041T6WreA9",
        "outputId": "d6be73de-fb04-4778-d614-03bef36da771"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(app.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527,
          "referenced_widgets": [
            "b899a3d50b214deaa4e5b0bc129c6cf7",
            "bfbedb5059694fc2871e267ba7da30af",
            "865889516814472f97abc1aed3df2de9",
            "8d1ed8bd858e49118e8c827deef92a25",
            "42277e3e0ae5492eb86da3edf17b026f",
            "fb5a1b55182f4c7d9de44c41d4922bc6",
            "3d4e4fea6ada4ee08ab9a14e6fcd9be6",
            "12a40606d48f4f929b6bf9116d694583",
            "76c25351e85440d78ae76ecf8de61646",
            "5e683dddf4e6404fa7827b5cc0afe293",
            "1894218904e8463e92ff01e33c64359e",
            "f88da17e30844a799738163db0ceb73e",
            "19daeaa4019c4664b52caff51d52d4e1",
            "51ae03c0d6ff463b971fa0f9a94646ba",
            "222787b73384454493cbc577f33d776a",
            "293ddf89c1a94b3c8217325df836952c",
            "b42a0c302e5e4de2ab61739c88943ad1",
            "2051311d29b7458ba3e9c3399051f7a7",
            "609b45c532cc405b803f3a773b074276",
            "1be86e7c16a946708406fc9c79c8a122",
            "c4d1b0e378b14df1ba37498d5d9b50ea",
            "0778f096fc9c462b92ead2744b300803",
            "89cd3fa50b24457196889a488501c6cf",
            "1f87691d116d4c27b9d2624b7ecb8662",
            "1747149a1feb457ba5ae454c5872ac84",
            "db49b509f8d1448aa118f4ffec9bc458",
            "95e757ac8ca34452a6133b0fa252c779",
            "474cdd72eddd422baf550e44665e27c7",
            "32997983f17d4c93b0adc3509c22f206",
            "73d43b574cad45c0859d7ced98d5d165",
            "5b1108edb3484c3c8fed5ebce3811191",
            "ac7bf0b3aea8437e94bd51d057287392",
            "45eb211ea3ad49209736fc18dd85b166",
            "f4c7ce8a95644c46a30352656d6cb69a",
            "c77510aae5db4b3aa30c267ca1d19265",
            "662469e09cee43b6ab41151dda81e5cf",
            "fddf917650bb447ca122457eb05ff625",
            "f556de596fda4dd1b4b4a2f2a04e2762",
            "cbf68a8c2d344112b611aa592f8971f3",
            "3fbef48dc9c44dd5823c3a1964263d62",
            "e4be42fed2694bd093a38a0af5518020",
            "4fe2b3ccac9d4c9e985f870d50be982a",
            "7f3bdd9e86974aa89a35cd94b8796b4b",
            "c96ee84291c447f884919790b6ab6a92",
            "505ac941e5f446f3a64d7ac53e29d2f4",
            "738b85f54dcf4457ba3ec06395dc4dfa",
            "b47291f4663c4d158ac7f8e043dc2b1e",
            "ee826b07b7514c29a01e3e2f37b5397f",
            "45d6c98cc3574737b8e743dd1a70e8f1",
            "5e065a7ab1d447e38127aa118f2fa9c2",
            "c4504abdf96149ccb7d0d38ea8db7a45",
            "f8bc6d776ad34f9aa8c69be464c9e4f9",
            "68904f9ff89b414aa17d59dffcc5e2b9",
            "e6104e5f5ac94fc9b6b4a1bae1d4bf4d",
            "e6380374aa984209bbf63fbeb6437d46"
          ]
        },
        "id": "maedniKWrnzW",
        "outputId": "e3dc9289-e4c7-4222-987f-babc599bd2c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['generate_summary']\n",
            "['generate_summary']\n",
            "['generate_summary']\n",
            "['generate_summary']\n",
            "['generate_summary']\n",
            "['generate_summary']\n",
            "['generate_summary']\n",
            "['generate_summary']\n",
            "['generate_summary']\n",
            "['generate_summary']\n",
            "['generate_summary']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b899a3d50b214deaa4e5b0bc129c6cf7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f88da17e30844a799738163db0ceb73e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89cd3fa50b24457196889a488501c6cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f4c7ce8a95644c46a30352656d6cb69a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "505ac941e5f446f3a64d7ac53e29d2f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['collect_summaries']\n",
            "['generate_final_summary']\n"
          ]
        }
      ],
      "source": [
        "async for step in app.astream(\n",
        "    {\"contents\": [doc.page_content for doc in split_docs]},\n",
        "    {\"recursion_limit\": 10},\n",
        "):\n",
        "    print(list(step.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7k8P8FssTIa",
        "outputId": "1790f4f1-fdf7-4017-c328-92176ee12b24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "content = step['generate_final_summary']['final_summary']\n",
        "type(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtIUDWj7t9_a"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", f\"\"\"Using the provided {content}, create a podcast script for a discussion between three characters: two males (Alex and Ben) and one female (Sophia). The discussion should simplify and explore the main ideas and practical applications of the content.\n",
        "\n",
        "Structure: Start with an engaging introduction by Sophia, followed by a back-and-forth conversation among the three characters.\n",
        "Tone: Keep it conversational, easy to understand, and relatable.\n",
        "Content Goals: Highlight key concepts, provide practical examples, and answer potential questions from the audience.\n",
        "Roles:\n",
        "Alex: Analytical and thoughtful.\n",
        "Ben: Curious and light-hearted.\n",
        "Sophia: Insightful and empathetic.\n",
        "End the script with a motivational takeaway and a sign-off message. Be sure to incorporate quotes or techniques mentioned in the content when relevant.\"\"\")]\n",
        ")\n",
        "\n",
        "prompt_ = f\"\"\"Using the provided {content}, create a podcast script for a discussion between three characters: two males (Alex and Ben) and one female (Sophia). The discussion should simplify and explore the main ideas and practical applications of the content.\n",
        "\n",
        "Structure: Start with an engaging introduction by Sophia, followed by a back-and-forth conversation among the three characters.\n",
        "Tone: Keep it conversational, easy to understand, and relatable.\n",
        "Content Goals: Highlight key concepts, provide practical examples, and answer potential questions from the audience.\n",
        "Roles:\n",
        "Alex: Analytical and thoughtful.\n",
        "Ben: Curious and light-hearted.\n",
        "Sophia: Insightful and empathetic.\n",
        "End the script with a motivational takeaway and a sign-off message. Be sure to incorporate quotes or techniques mentioned in the content when relevant.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate chain\n",
        "result = llm.invoke(prompt_)\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R-a7CqCtUwe6",
        "outputId": "78e19fab-8067-4504-92c6-0f1899c6e84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is a podcast script based on the provided themes:\n",
            "\n",
            "**Podcast Title:** \"Decoding Deep Learning for NLP\"\n",
            "\n",
            "**Intro Music and Introduction by Sophia**\n",
            "\n",
            "Sophia: Welcome to \"Decoding Deep Learning for NLP\"! I'm Sophia, and I'm excited to be hosting this conversation with Alex and Ben. Today, we're diving into the fascinating world of deep learning and its applications in natural language processing. From transformer architecture to attention mechanisms, we'll break down complex concepts into actionable insights. So, let's get started!\n",
            "\n",
            "**Segment 1: Transformer Architecture and Mechanisms**\n",
            "\n",
            "Alex: Sophia, can you start by explaining what's so special about the Transformer model?\n",
            "\n",
            "Sophia: Absolutely, Alex. The Transformer model is a game-changer in NLP. It's primarily used for sequence-to-sequence tasks, like machine translation. What sets it apart is its self-attention mechanism, which allows it to process input sequences in parallel.\n",
            "\n",
            "Ben: That sounds like a superpower! Can you give us an example of how it works?\n",
            "\n",
            "Sophia: Imagine you're translating a sentence from English to German. The Transformer model uses self-attention to weigh the importance of each word in the sentence, relative to every other word. This helps it capture context and meanings more effectively.\n",
            "\n",
            "Alex: That's fascinating. And what about multi-head attention? How does that differ from self-attention?\n",
            "\n",
            "Sophia: Ah, great question, Alex. Multi-head attention is an extension of self-attention. It allows the model to capture different types of relationships between words, like syntactic and semantic relationships, by computing attention weights multiple times.\n",
            "\n",
            "**Segment 2: Attention Mechanisms**\n",
            "\n",
            "Ben: I'm still wrapping my head around attention mechanisms. Can you explain why they're so crucial in NLP?\n",
            "\n",
            "Sophia: Attention mechanisms are essential because they enable models to focus on specific parts of the input data that are relevant to the task at hand. This leads to more accurate and efficient processing.\n",
            "\n",
            "Alex: That makes sense. And what about the different types of attention mechanisms? How do they differ?\n",
            "\n",
            "Sophia: Well, there's additive attention, dot-product attention, and scaled dot-product attention. Each has its strengths and weaknesses, but they all boil down to computing weights that represent the importance of different input elements.\n",
            "\n",
            "**Segment 3: Sequence-to-Sequence Models and Machine Translation**\n",
            "\n",
            "Ben: Sophia, can you tell us more about sequence-to-sequence models and their applications in machine translation?\n",
            "\n",
            "Sophia: Sequence-to-sequence models are perfect for tasks that involve generating output sequences, like machine translation. The Transformer model has revolutionized machine translation by achieving state-of-the-art results in many languages.\n",
            "\n",
            "Alex: That's impressive. How do these models handle tasks like English-to-German translation?\n",
            "\n",
            "Sophia: The encoder-decoder structure is key. The encoder processes the input sequence, and the decoder generates the output sequence. The self-attention mechanism helps the model capture context and relationships between words.\n",
            "\n",
            "**Segment 4: Model Design, Optimization, and Interpretability**\n",
            "\n",
            "Alex: Sophia, how do model design choices impact performance? What are some best practices?\n",
            "\n",
            "Sophia: Ah, great question, Alex. Model design choices, like the use of multi-head attention and positional encoding, can significantly impact performance. It's essential to experiment and find the right balance of components for your specific task.\n",
            "\n",
            "Ben: That's really interesting. What about model interpretability? How can we understand what's going on inside these complex models?\n",
            "\n",
            "Sophia: Model interpretability is crucial. Techniques like inspecting attention distributions can help us understand how the model is making predictions. This is especially important in high-stakes applications like healthcare or finance.\n",
            "\n",
            "**Segment 5: Conclusion and Takeaway**\n",
            "\n",
            "Sophia: As we wrap up this conversation, I want to leave you with a quote from Vaswani et al.'s paper on the Transformer model: \"The Transformer model relies entirely on self-attention mechanisms, dispensing with recurrence and convolutions entirely.\" This quote highlights the power of self-attention in revolutionizing NLP tasks.\n",
            "\n",
            "Alex: That's a great takeaway, Sophia. What I've learned today is that deep learning models are not just complex algorithms; they're tools that can be tuned and optimized to achieve remarkable results.\n",
            "\n",
            "Ben: And I think what resonated with me is that these models are not just about processing language; they're about understanding the nuances of human communication.\n",
            "\n",
            "Sophia: That's beautifully said, Ben. As we continue to explore the potential of deep learning in NLP, let's remember to stay curious, keep learning, and apply these concepts to real-world problems.\n",
            "\n",
            "**Outro Music and Sign-off**\n",
            "\n",
            "Sophia: Thanks for tuning in to \"Decoding Deep Learning for NLP\"! Join us next time for more conversations about AI, machine learning, and natural language processing. Until then, stay informed, stay curious, and keep on learning!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "09a8aiR9VGl5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b899a3d50b214deaa4e5b0bc129c6cf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfbedb5059694fc2871e267ba7da30af",
              "IPY_MODEL_865889516814472f97abc1aed3df2de9",
              "IPY_MODEL_8d1ed8bd858e49118e8c827deef92a25"
            ],
            "layout": "IPY_MODEL_42277e3e0ae5492eb86da3edf17b026f"
          }
        },
        "bfbedb5059694fc2871e267ba7da30af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb5a1b55182f4c7d9de44c41d4922bc6",
            "placeholder": "​",
            "style": "IPY_MODEL_3d4e4fea6ada4ee08ab9a14e6fcd9be6",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "865889516814472f97abc1aed3df2de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12a40606d48f4f929b6bf9116d694583",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_76c25351e85440d78ae76ecf8de61646",
            "value": 26
          }
        },
        "8d1ed8bd858e49118e8c827deef92a25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e683dddf4e6404fa7827b5cc0afe293",
            "placeholder": "​",
            "style": "IPY_MODEL_1894218904e8463e92ff01e33c64359e",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.75kB/s]"
          }
        },
        "42277e3e0ae5492eb86da3edf17b026f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb5a1b55182f4c7d9de44c41d4922bc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4e4fea6ada4ee08ab9a14e6fcd9be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12a40606d48f4f929b6bf9116d694583": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76c25351e85440d78ae76ecf8de61646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e683dddf4e6404fa7827b5cc0afe293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1894218904e8463e92ff01e33c64359e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f88da17e30844a799738163db0ceb73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19daeaa4019c4664b52caff51d52d4e1",
              "IPY_MODEL_51ae03c0d6ff463b971fa0f9a94646ba",
              "IPY_MODEL_222787b73384454493cbc577f33d776a"
            ],
            "layout": "IPY_MODEL_293ddf89c1a94b3c8217325df836952c"
          }
        },
        "19daeaa4019c4664b52caff51d52d4e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42a0c302e5e4de2ab61739c88943ad1",
            "placeholder": "​",
            "style": "IPY_MODEL_2051311d29b7458ba3e9c3399051f7a7",
            "value": "vocab.json: 100%"
          }
        },
        "51ae03c0d6ff463b971fa0f9a94646ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_609b45c532cc405b803f3a773b074276",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1be86e7c16a946708406fc9c79c8a122",
            "value": 1042301
          }
        },
        "222787b73384454493cbc577f33d776a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d1b0e378b14df1ba37498d5d9b50ea",
            "placeholder": "​",
            "style": "IPY_MODEL_0778f096fc9c462b92ead2744b300803",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 4.72MB/s]"
          }
        },
        "293ddf89c1a94b3c8217325df836952c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b42a0c302e5e4de2ab61739c88943ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2051311d29b7458ba3e9c3399051f7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "609b45c532cc405b803f3a773b074276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1be86e7c16a946708406fc9c79c8a122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4d1b0e378b14df1ba37498d5d9b50ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0778f096fc9c462b92ead2744b300803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89cd3fa50b24457196889a488501c6cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f87691d116d4c27b9d2624b7ecb8662",
              "IPY_MODEL_1747149a1feb457ba5ae454c5872ac84",
              "IPY_MODEL_db49b509f8d1448aa118f4ffec9bc458"
            ],
            "layout": "IPY_MODEL_95e757ac8ca34452a6133b0fa252c779"
          }
        },
        "1f87691d116d4c27b9d2624b7ecb8662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_474cdd72eddd422baf550e44665e27c7",
            "placeholder": "​",
            "style": "IPY_MODEL_32997983f17d4c93b0adc3509c22f206",
            "value": "merges.txt: 100%"
          }
        },
        "1747149a1feb457ba5ae454c5872ac84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d43b574cad45c0859d7ced98d5d165",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b1108edb3484c3c8fed5ebce3811191",
            "value": 456318
          }
        },
        "db49b509f8d1448aa118f4ffec9bc458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac7bf0b3aea8437e94bd51d057287392",
            "placeholder": "​",
            "style": "IPY_MODEL_45eb211ea3ad49209736fc18dd85b166",
            "value": " 456k/456k [00:00&lt;00:00, 2.03MB/s]"
          }
        },
        "95e757ac8ca34452a6133b0fa252c779": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474cdd72eddd422baf550e44665e27c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32997983f17d4c93b0adc3509c22f206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73d43b574cad45c0859d7ced98d5d165": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b1108edb3484c3c8fed5ebce3811191": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ac7bf0b3aea8437e94bd51d057287392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45eb211ea3ad49209736fc18dd85b166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4c7ce8a95644c46a30352656d6cb69a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c77510aae5db4b3aa30c267ca1d19265",
              "IPY_MODEL_662469e09cee43b6ab41151dda81e5cf",
              "IPY_MODEL_fddf917650bb447ca122457eb05ff625"
            ],
            "layout": "IPY_MODEL_f556de596fda4dd1b4b4a2f2a04e2762"
          }
        },
        "c77510aae5db4b3aa30c267ca1d19265": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbf68a8c2d344112b611aa592f8971f3",
            "placeholder": "​",
            "style": "IPY_MODEL_3fbef48dc9c44dd5823c3a1964263d62",
            "value": "tokenizer.json: 100%"
          }
        },
        "662469e09cee43b6ab41151dda81e5cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4be42fed2694bd093a38a0af5518020",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fe2b3ccac9d4c9e985f870d50be982a",
            "value": 1355256
          }
        },
        "fddf917650bb447ca122457eb05ff625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f3bdd9e86974aa89a35cd94b8796b4b",
            "placeholder": "​",
            "style": "IPY_MODEL_c96ee84291c447f884919790b6ab6a92",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 28.0MB/s]"
          }
        },
        "f556de596fda4dd1b4b4a2f2a04e2762": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbf68a8c2d344112b611aa592f8971f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fbef48dc9c44dd5823c3a1964263d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4be42fed2694bd093a38a0af5518020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fe2b3ccac9d4c9e985f870d50be982a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f3bdd9e86974aa89a35cd94b8796b4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c96ee84291c447f884919790b6ab6a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "505ac941e5f446f3a64d7ac53e29d2f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_738b85f54dcf4457ba3ec06395dc4dfa",
              "IPY_MODEL_b47291f4663c4d158ac7f8e043dc2b1e",
              "IPY_MODEL_ee826b07b7514c29a01e3e2f37b5397f"
            ],
            "layout": "IPY_MODEL_45d6c98cc3574737b8e743dd1a70e8f1"
          }
        },
        "738b85f54dcf4457ba3ec06395dc4dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e065a7ab1d447e38127aa118f2fa9c2",
            "placeholder": "​",
            "style": "IPY_MODEL_c4504abdf96149ccb7d0d38ea8db7a45",
            "value": "config.json: 100%"
          }
        },
        "b47291f4663c4d158ac7f8e043dc2b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8bc6d776ad34f9aa8c69be464c9e4f9",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68904f9ff89b414aa17d59dffcc5e2b9",
            "value": 665
          }
        },
        "ee826b07b7514c29a01e3e2f37b5397f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6104e5f5ac94fc9b6b4a1bae1d4bf4d",
            "placeholder": "​",
            "style": "IPY_MODEL_e6380374aa984209bbf63fbeb6437d46",
            "value": " 665/665 [00:00&lt;00:00, 44.0kB/s]"
          }
        },
        "45d6c98cc3574737b8e743dd1a70e8f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e065a7ab1d447e38127aa118f2fa9c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4504abdf96149ccb7d0d38ea8db7a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8bc6d776ad34f9aa8c69be464c9e4f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68904f9ff89b414aa17d59dffcc5e2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6104e5f5ac94fc9b6b4a1bae1d4bf4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6380374aa984209bbf63fbeb6437d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}